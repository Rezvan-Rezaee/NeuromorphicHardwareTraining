{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aefb188",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_weight, max_weight = -0.7, 0.7\n",
    "num_weight_levels = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f71316",
   "metadata": {},
   "source": [
    "# Setup and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7605bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch, warnings\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bb3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.5071, 0.4867, 0.4408)\n",
    "std  = (0.2675, 0.2565, 0.2761)\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandAugment(num_ops=2, magnitude=9),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=0),\n",
    "])\n",
    "\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "train_set = datasets.CIFAR100(root=\"./data\", train=True, download=True, transform=train_tf)\n",
    "test_set  = datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=test_tf)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_set, batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6429dc60",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurrentConv2d(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, stride=1, padding=0, bias=False, width_scale=1.0):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, k, stride=stride, padding=padding, bias=bias)\n",
    "        self.width_scale = float(width_scale)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x interpreted as pulse-width signal scaling current\n",
    "        return self.conv(x * self.width_scale)\n",
    "\n",
    "\n",
    "class CurrentLinear(nn.Module):\n",
    "    def __init__(self, in_f, out_f, bias=True, width_scale=1.0):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_f, out_f, bias=bias)\n",
    "        self.width_scale = float(width_scale)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x * self.width_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8ef08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WRNBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_ch)\n",
    "        self.conv1 = CurrentConv2d(in_ch, out_ch, 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "        self.conv2 = CurrentConv2d(out_ch, out_ch, 3, stride=1, padding=1, bias=False)\n",
    "        self.dropout = float(dropout)\n",
    "\n",
    "        self.shortcut = nn.Identity()\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.shortcut = nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x), inplace=True)\n",
    "        out = self.conv1(out)\n",
    "        out = F.relu(self.bn2(out), inplace=True)\n",
    "        if self.dropout > 0:\n",
    "            out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return out + self.shortcut(x)\n",
    "\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth=28, widen_factor=10, dropout=0.0, num_classes=100):\n",
    "        super().__init__()\n",
    "        assert (depth - 4) % 6 == 0\n",
    "        n = (depth - 4) // 6\n",
    "        k = widen_factor\n",
    "        ch = [16, 16*k, 32*k, 64*k]\n",
    "\n",
    "        self.conv1 = CurrentConv2d(3, ch[0], 3, stride=1, padding=1, bias=False)\n",
    "        self.block1 = self._make_group(ch[0], ch[1], n, stride=1, dropout=dropout)\n",
    "        self.block2 = self._make_group(ch[1], ch[2], n, stride=2, dropout=dropout)\n",
    "        self.block3 = self._make_group(ch[2], ch[3], n, stride=2, dropout=dropout)\n",
    "        self.bn = nn.BatchNorm2d(ch[3])\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = CurrentLinear(ch[3], num_classes, bias=True)\n",
    "\n",
    "        # He init\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "    def _make_group(self, in_ch, out_ch, n, stride, dropout):\n",
    "        layers = [WRNBlock(in_ch, out_ch, stride=stride, dropout=dropout)]\n",
    "        for _ in range(1, n):\n",
    "            layers.append(WRNBlock(out_ch, out_ch, stride=1, dropout=dropout))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = F.relu(self.bn(x), inplace=True)\n",
    "        x = self.pool(x).flatten(1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskW(w: torch.Tensor) -> torch.Tensor:\n",
    "    w = torch.clamp(w, min=min_weight, max=max_weight)\n",
    "    step = (max_weight - min_weight) / (num_weight_levels - 1)\n",
    "    return ((w - min_weight) / step).round() * step + min_weight\n",
    "\n",
    "def maskW_ste(w: torch.Tensor) -> torch.Tensor:\n",
    "    # Forward: quantized weights\n",
    "    w_q = maskW(w)\n",
    "    # Backward: pretend quantization was identity (straight-through estimator)\n",
    "    return w + (w_q - w).detach()\n",
    "\n",
    "def one_hot(y, num_classes, device):\n",
    "    return F.one_hot(y, num_classes=num_classes).float().to(device)\n",
    "\n",
    "def mixup_cutmix(x, y, num_classes, mixup_alpha=0.2, cutmix_alpha=1.0, p=1.0):\n",
    "    if random.random() > p:\n",
    "        return x, one_hot(y, num_classes, x.device)\n",
    "\n",
    "    use_cutmix = random.random() < 0.5\n",
    "    if use_cutmix:\n",
    "        lam = torch.distributions.Beta(cutmix_alpha, cutmix_alpha).sample().item()\n",
    "        rand_index = torch.randperm(x.size(0), device=x.device)\n",
    "        y_a = one_hot(y, num_classes, x.device)\n",
    "        y_b = one_hot(y[rand_index], num_classes, x.device)\n",
    "\n",
    "        bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "        x[:, :, bby1:bby2, bbx1:bbx2] = x[rand_index, :, bby1:bby2, bbx1:bbx2]\n",
    "        lam = 1.0 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size(-1) * x.size(-2)))\n",
    "        y_mix = lam * y_a + (1 - lam) * y_b\n",
    "        return x, y_mix\n",
    "    else:\n",
    "        lam = torch.distributions.Beta(mixup_alpha, mixup_alpha).sample().item()\n",
    "        rand_index = torch.randperm(x.size(0), device=x.device)\n",
    "        x_mix = lam * x + (1 - lam) * x[rand_index]\n",
    "        y_a = one_hot(y, num_classes, x.device)\n",
    "        y_b = one_hot(y[rand_index], num_classes, x.device)\n",
    "        y_mix = lam * y_a + (1 - lam) * y_b\n",
    "        return x_mix, y_mix\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    # size: (B, C, H, W)\n",
    "    W = size[3]\n",
    "    H = size[2]\n",
    "    cut_rat = math.sqrt(1.0 - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "    cx = random.randint(0, W - 1)\n",
    "    cy = random.randint(0, H - 1)\n",
    "    bbx1 = max(cx - cut_w // 2, 0)\n",
    "    bby1 = max(cy - cut_h // 2, 0)\n",
    "    bbx2 = min(cx + cut_w // 2, W)\n",
    "    bby2 = min(cy + cut_h // 2, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def soft_ce(logits, y_soft):\n",
    "    logp = F.log_softmax(logits, dim=1)\n",
    "    return -(y_soft * logp).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "k: float = 1.38e-23   # Boltzmann constant (J/K)\n",
    "q: float = 1.602176634e-19\n",
    "T_r: float = 300\n",
    "n: float = 1.5\n",
    "k_mu: float = 1.5\n",
    "k_vt: float = 1e-3 # Typical value for threshold voltage temperature dependence (in V/K)\n",
    "Tr = 300\n",
    "\n",
    "def thermal_voltage(T):\n",
    "    return k * T / q\n",
    "\n",
    "def Id_subthreshold(W, L, mu, Cox, Vth, VGS, VDS, T, n):\n",
    "    Vt = thermal_voltage(T)\n",
    "    Is0 = (W / L) * mu * Cox * (Vt**2) * np.exp(1.8)\n",
    "    return Is0 * np.exp((VGS - Vth) / (n * Vt)) * (1 - np.exp(-VDS / Vt))\n",
    "\n",
    "class SubthresholdPVTNoise(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        params: dict with\n",
    "            W, L, mu, Cox, Vth, VGS, VDS, T, n\n",
    "        sigmas: dict with\n",
    "            W, L, mu, Cox, Vth, VDS (normal std)\n",
    "            dT (uniform half-range)\n",
    "        \"\"\"\n",
    "        #self.p = params\n",
    "        self.W   = 44e-9\n",
    "        self.L   = 22e-9\n",
    "        self.mu  = 0.03\n",
    "        self.Cox = 0.03\n",
    "        self.Vth = 0.35\n",
    "        self.VGS = 0.25\n",
    "        self.VDS = 0.8\n",
    "        self.T0  = 310.0\n",
    "        self.n   = 1.5\n",
    "        self.dId_dW_value = 0.0\n",
    "        self.dId_dL_value = 0.0\n",
    "        self.dId_dmu_value = 0.0\n",
    "        self.dId_dCox_value = 0.0\n",
    "        self.dId_dVth_value = 0.0\n",
    "        self.dId_dVDS_value = 0.0\n",
    "        self.dId_dT_value = 0.0\n",
    "        self.s = {\n",
    "            \"W\":   0.10 * self.W,\n",
    "            \"L\":   0.10 * self.L,\n",
    "            \"mu\":  0.10 * self.mu,\n",
    "            \"Cox\": 0.10 * self.Cox,\n",
    "            \"Vth\": 0.10 * self.Vth,\n",
    "            \"VDS\": 0.10 * self.VDS,\n",
    "            \"T_min\": 248,\n",
    "            \"T_max\": 398,\n",
    "        }\n",
    "\n",
    "    def dId_dW(self):\n",
    "        Vt = thermal_voltage(self.T0)\n",
    "        return (self.mu * self.Cox * Vt**2 / self.L) * np.exp(1.8) * \\\n",
    "            np.exp((self.VGS - self.Vth) / (self.n * Vt)) * (1 - np.exp(-self.VDS / Vt))\n",
    "\n",
    "    def dId_dmu(self):\n",
    "        Vt = thermal_voltage(self.T0)\n",
    "        return (self.W * self.Cox * Vt**2 / self.L) * np.exp(1.8) * \\\n",
    "            np.exp((self.VGS - self.Vth) / (self.n * Vt)) * (1 - np.exp(-self.VDS / Vt))\n",
    "\n",
    "    def dId_dCox(self):\n",
    "        Vt = thermal_voltage(self.T0)\n",
    "        return (self.W * self.mu * Vt**2 / self.L) * np.exp(1.8) * \\\n",
    "            np.exp((self.VGS - self.Vth) / (self.n * Vt)) * (1 - np.exp(-self.VDS / Vt))\n",
    "\n",
    "    def dId_dL(self):\n",
    "        Vt = thermal_voltage(self.T0)\n",
    "        return -(self.W * self.mu * self.Cox * Vt**2 / self.L**2) * np.exp(1.8) * \\\n",
    "                np.exp((self.VGS - self.Vth) / (self.n * Vt)) * (1 - np.exp(-self.VDS / Vt))\n",
    "    \n",
    "    def dId_dVDS(self):\n",
    "        Vt = thermal_voltage(self.T0)\n",
    "        Is0 = (self.W / self.L) * self.mu * self.Cox * (Vt**2) * np.exp(1.8)\n",
    "        return Is0 * np.exp((self.VGS - self.Vth) / (self.n * Vt)) * (np.exp(-self.VDS / Vt) / Vt)\n",
    "    \n",
    "    def dId_dVth(self):\n",
    "        Id = Id_subthreshold(self.W, self.L, self.mu, self.Cox, self.Vth, self.VGS, self.VDS, self.T0, self.n)\n",
    "        Vt = thermal_voltage(self.T0)\n",
    "        return (-1 / (self.n * Vt)) * Id * np.exp((self.VGS - self.Vth) / (self.n * Vt)) * \\\n",
    "            (1 - np.exp(-self.VDS / Vt))\n",
    "\n",
    "    def dId_dT(self):\n",
    "        Vt = thermal_voltage(self.T0)\n",
    "        Id = Id_subthreshold(self.W, self.L, self.mu, self.Cox, self.Vth, self.VGS, self.VDS, self.T0, self.n)\n",
    "\n",
    "        term1 = k_mu - (( k_vt * self.T0) / (self.n * Vt)) * Id\n",
    "        term2 = (1 - np.exp(-self.VDS / Vt)) * Tr**(-k_mu) * self.T0**(k_mu - 1)\n",
    "        term3 = np.exp((self.VGS - self.Vth * Tr - k_vt * (self.T0-Tr)) / (self.n * Vt))\n",
    "        return Id * (term1 + term2 + term3)\n",
    "\n",
    "    def update_params(self):\n",
    "        self.dId_dW_value = self.dId_dW()\n",
    "        self.dId_dL_value = self.dId_dL()\n",
    "        self.dId_dmu_value = self.dId_dmu()\n",
    "        self.dId_dCox_value = self.dId_dCox()\n",
    "        self.dId_dVth_value = self.dId_dVth()\n",
    "        self.dId_dVDS_value = self.dId_dVDS()\n",
    "        self.dId_dT_value = self.dId_dT()\n",
    "\n",
    "    def forward(self, Id0):\n",
    "        \"\"\"\n",
    "        Id0: torch.Tensor (any shape)\n",
    "        returns: noisy Id tensor (same shape)\n",
    "        \"\"\"\n",
    "        device, dtype = Id0.device, Id0.dtype\n",
    "        self.update_params()\n",
    "\n",
    "        # ---- sample parameter variations ----\n",
    "        dW   = torch.normal(0.0, self.s[\"W\"],   size=Id0.shape, device=device, dtype=dtype)\n",
    "        dL   = torch.normal(0.0, self.s[\"L\"],   size=Id0.shape, device=device, dtype=dtype)\n",
    "        dmu  = torch.normal(0.0, self.s[\"mu\"],  size=Id0.shape, device=device, dtype=dtype)\n",
    "        dCox = torch.normal(0.0, self.s[\"Cox\"], size=Id0.shape, device=device, dtype=dtype)\n",
    "        dVth = torch.normal(0.0, self.s[\"Vth\"], size=Id0.shape, device=device, dtype=dtype)\n",
    "        dVDS = torch.normal(0.0, self.s[\"VDS\"], size=Id0.shape, device=device, dtype=dtype)\n",
    "        dT   = torch.empty_like(Id0).uniform_(self.s[\"T_min\"], self.s[\"T_max\"])\n",
    "        dT  = dT - self.T0\n",
    "\n",
    "        # dW = 0\n",
    "        # dL = 0\n",
    "        # dmu = 0\n",
    "        # dCox = 0    \n",
    "        # dVth = 0\n",
    "        # dVDS = 0\n",
    "        # dT = 0\n",
    "\n",
    "        # ---- analytical partial derivatives ----\n",
    "        dId = (\n",
    "            self.dId_dW_value           * dW   +\n",
    "            self.dId_dL_value           * dL   +\n",
    "            self.dId_dmu_value          * dmu  +\n",
    "            self.dId_dCox_value         * dCox +\n",
    "            self.dId_dVth_value         * dVth +\n",
    "            self.dId_dVDS_value * dVDS +\n",
    "            self.dId_dT_value * dT\n",
    "        )\n",
    "\n",
    "        return Id0 + dId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb93dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QATConv2d_no_other_noise(nn.Conv2d):\n",
    "    def forward(self, x):\n",
    "        w = maskW_ste(self.weight) if self.training else maskW(self.weight)\n",
    "        return F.conv2d(x, w, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "class QATLinear_no_other_noise(nn.Linear):\n",
    "    def forward(self, x):\n",
    "        w = maskW_ste(self.weight) if self.training else maskW(self.weight)\n",
    "        return F.linear(x, w, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f149f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QATConv2d(nn.Conv2d):\n",
    "    def __init__(self, *args, noise=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Register as a submodule so it moves to GPU + appears in state_dict\n",
    "        self.noise = noise if noise is not None else SubthresholdPVTNoise()\n",
    "        self.noise.update_params()\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = maskW_ste(self.weight) if self.training else maskW(self.weight)\n",
    "\n",
    "        # Add noise in forward pass (typically only during training)\n",
    "        if self.training:\n",
    "            w = self.noise(w)   # calls SubthresholdPVTNoise.forward(w)\n",
    "\n",
    "        return F.conv2d(x, w, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "\n",
    "class QATLinear(nn.Linear):\n",
    "    def __init__(self, *args, noise=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.noise = noise if noise is not None else SubthresholdPVTNoise()\n",
    "        self.noise.update_params()\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = maskW_ste(self.weight) if self.training else maskW(self.weight)\n",
    "        if self.training:\n",
    "            w = self.noise(w)\n",
    "        return F.linear(x, w, self.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4153c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftLIFRate(nn.Module):\n",
    "    def __init__(self, theta=0.0, gain=1.0, tau_rc=0.02, tau_ref=0.002, eps=1e-4):\n",
    "        super().__init__()\n",
    "        self.theta = nn.Parameter(torch.tensor(float(theta)))\n",
    "        self.gain  = nn.Parameter(torch.tensor(float(gain)))\n",
    "        self.tau_rc  = float(tau_rc)\n",
    "        self.tau_ref = float(tau_ref)\n",
    "        self.eps = float(eps)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Force the critical math to FP32 to avoid AMP/FP16 inf->nan gradients\n",
    "        z32 = z.float()\n",
    "        u = (self.gain.float()) * (z32 - self.theta.float())\n",
    "\n",
    "        # J = 1 + softplus(u) >= 1\n",
    "        Jm1 = F.softplus(u)                       # this is (J-1)\n",
    "        Jm1 = torch.clamp(Jm1, min=self.eps)      # prevents divide-by-0 / inf grads\n",
    "\n",
    "        # log(1 + 1/(J-1))\n",
    "        denom = self.tau_ref + self.tau_rc * torch.log1p(1.0 / Jm1)\n",
    "        rate  = 1.0 / denom\n",
    "\n",
    "        r = rate * self.tau_ref                   # normalize to [0,1]\n",
    "        r = torch.clamp(r, 0.0, 1.0)\n",
    "\n",
    "        return r.to(dtype=z.dtype)                # restore original dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WRNBlock_Rate_noQuant(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride, dropout=0.0, act=None):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_ch)\n",
    "        self.act1 = act if act is not None else SoftLIFRate()\n",
    "        self.conv1 = CurrentConv2d(in_ch, out_ch, 3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "        self.act2 = act if act is not None else SoftLIFRate()\n",
    "        self.conv2 = CurrentConv2d(out_ch, out_ch, 3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        self.dropout = float(dropout)\n",
    "\n",
    "        self.shortcut = nn.Identity()\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.shortcut = nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.act1(self.bn1(x))\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.act2(self.bn2(out))\n",
    "        if self.dropout > 0:\n",
    "            out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        return out + self.shortcut(x)\n",
    "class WideResNet_SoftLIFRate_noQuant(nn.Module):\n",
    "    def __init__(self, depth=28, widen_factor=10, dropout=0.0, num_classes=100,\n",
    "                 in_channels=3, act_theta=0.0, act_gain=1.0, tau_rc=0.02, tau_ref=0.002):\n",
    "        super().__init__()\n",
    "        assert (depth - 4) % 6 == 0\n",
    "        n = (depth - 4) // 6\n",
    "        k = widen_factor\n",
    "        ch = [16, 16*k, 32*k, 64*k]\n",
    "\n",
    "        # one shared config, but separate modules get created per block below\n",
    "        def make_act():\n",
    "            return SoftLIFRate(theta=act_theta, gain=act_gain, tau_rc=tau_rc, tau_ref=tau_ref)\n",
    "\n",
    "        self.conv1 = CurrentConv2d(in_channels, ch[0], 3, stride=1, padding=1, bias=False)\n",
    "        self.block1 = self._make_group(ch[0], ch[1], n, stride=1, dropout=dropout, make_act=make_act)\n",
    "        self.block2 = self._make_group(ch[1], ch[2], n, stride=2, dropout=dropout, make_act=make_act)\n",
    "        self.block3 = self._make_group(ch[2], ch[3], n, stride=2, dropout=dropout, make_act=make_act)\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(ch[3])\n",
    "        self.act_out = make_act()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = CurrentLinear(ch[3], num_classes, bias=True)\n",
    "\n",
    "    def _make_group(self, in_ch, out_ch, n, stride, dropout, make_act):\n",
    "        layers = [WRNBlock_Rate_noQuant(in_ch, out_ch, stride=stride, dropout=dropout, act=make_act())]\n",
    "        for _ in range(1, n):\n",
    "            layers.append(WRNBlock_Rate_noQuant(out_ch, out_ch, stride=1, dropout=dropout, act=make_act()))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.act_out(self.bn(x))\n",
    "        x = self.pool(x).flatten(1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WRNBlock_Rate(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride, dropout=0.0, act=None):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_ch)\n",
    "        self.act1 = act if act is not None else SoftLIFRate()\n",
    "        self.conv1 = QATConv2d(in_ch, out_ch, 3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "        self.act2 = act if act is not None else SoftLIFRate()\n",
    "        self.conv2 = QATConv2d(out_ch, out_ch, 3, stride=1, padding=1, bias=False)\n",
    "        self.dropout = float(dropout)\n",
    "\n",
    "        self.shortcut = nn.Identity()\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.shortcut = QATConv2d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.act1(self.bn1(x))\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.act2(self.bn2(out))\n",
    "        if self.dropout > 0:\n",
    "            out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        return out + self.shortcut(x)\n",
    "class WideResNet_SoftLIFRate(nn.Module):\n",
    "    def __init__(self, depth=16, widen_factor=10, dropout=0.0, num_classes=100,\n",
    "                 in_channels=3, act_theta=0.0, act_gain=1.0, tau_rc=0.02, tau_ref=0.002):\n",
    "        super().__init__()\n",
    "        assert (depth - 4) % 6 == 0\n",
    "        n = (depth - 4) // 6\n",
    "        k = widen_factor\n",
    "        ch = [16, 16*k, 32*k, 64*k]\n",
    "\n",
    "        # one shared config, but separate modules get created per block below\n",
    "        def make_act():\n",
    "            return SoftLIFRate(theta=act_theta, gain=act_gain, tau_rc=tau_rc, tau_ref=tau_ref)\n",
    "\n",
    "        self.conv1 = QATConv2d(in_channels, ch[0], 3, stride=1, padding=1, bias=False)\n",
    "        self.block1 = self._make_group(ch[0], ch[1], n, stride=1, dropout=dropout, make_act=make_act)\n",
    "        self.block2 = self._make_group(ch[1], ch[2], n, stride=2, dropout=dropout, make_act=make_act)\n",
    "        self.block3 = self._make_group(ch[2], ch[3], n, stride=2, dropout=dropout, make_act=make_act)\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(ch[3])\n",
    "        self.act_out = make_act()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = QATLinear(ch[3], num_classes, bias=True)\n",
    "\n",
    "    def _make_group(self, in_ch, out_ch, n, stride, dropout, make_act):\n",
    "        layers = [WRNBlock_Rate(in_ch, out_ch, stride=stride, dropout=dropout, act=make_act())]\n",
    "        for _ in range(1, n):\n",
    "            layers.append(WRNBlock_Rate(out_ch, out_ch, stride=1, dropout=dropout, act=make_act()))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.act_out(self.bn(x))\n",
    "        x = self.pool(x).flatten(1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c620122",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def clamp_weights_(model, lo=min_weight, hi=max_weight):\n",
    "    # Clamp only \"synaptic\" weights (Conv/Linear). Leave BN alone.\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            if m.weight is not None:\n",
    "                m.weight.clamp_(lo, hi)\n",
    "            if getattr(m, \"bias\", None) is not None:\n",
    "                m.bias.clamp_(lo, hi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4924b4f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = WideResNet(depth=16, widen_factor=10, dropout=0.0, num_classes=100).to(device)\n",
    "\n",
    "# Label smoothing helps CIFAR-100; if using soft labels (mixup), weâ€™ll use soft CE anyway.\n",
    "label_smoothing = 0.1\n",
    "criterion_hard = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "epochs = 200\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "use_amp = (device == \"cuda\")\n",
    "scaler = GradScaler(device, enabled=use_amp)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"`torch.cuda.amp.*` is deprecated.*\")\n",
    "print(\"autocast module:\", autocast.__module__)\n",
    "print(\"GradScaler module:\", GradScaler.__module__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion_hard(logits, y)\n",
    "        loss_sum += float(loss) * x.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += int((pred == y).sum())\n",
    "        total += y.numel()\n",
    "    return loss_sum / total, correct / total\n",
    "\n",
    "def train_one_epoch(model, loader, use_mix=True):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if use_mix:\n",
    "            x, y_soft = mixup_cutmix(x, y, num_classes=100, mixup_alpha=0.2, cutmix_alpha=1.0, p=1.0)\n",
    "        else:\n",
    "            y_soft = None\n",
    "\n",
    "        with autocast(enabled=use_amp, device_type=device.type):\n",
    "            logits = model(x)\n",
    "            if y_soft is None:\n",
    "                loss = criterion_hard(logits, y)\n",
    "            else:\n",
    "                loss = soft_ce(logits, y_soft)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        clamp_weights_(model, -0.7, 0.7)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += float(loss) * x.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += int((pred == y).sum())\n",
    "        total += y.numel()\n",
    "        print(f\"\\r  Batch train loss: {running_loss / total:.4f}\", end=\"\")\n",
    "\n",
    "    return running_loss / total, correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353aad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c60478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_load = torch.load(\"checkpoints/bp4snn/digLif/epoch_049_acc_24.78.pt\")\n",
    "model.load_state_dict(weights_load[\"state_dict\"], strict=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f127c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0.0\n",
    "for ep in range(1, epochs + 1):\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_loader, use_mix=True)\n",
    "    te_loss, te_acc = evaluate(model, test_loader)\n",
    "    scheduler.step()\n",
    "    best_acc = max(best_acc, te_acc)\n",
    "    print(f\"Epoch {ep:3d} | train loss {tr_loss:.4f} acc {tr_acc*100:5.2f}%\"\n",
    "            f\" | test loss {te_loss:.4f} acc {te_acc*100:5.2f}%\")\n",
    "\n",
    "    if ep % 10 == 0 or ep == 1:\n",
    "        print(f\"Epoch {ep:3d} | train loss {tr_loss:.4f} acc {tr_acc*100:5.2f}%\"\n",
    "              f\" | test loss {te_loss:.4f} acc {te_acc*100:5.2f}% | best {best_acc*100:5.2f}%\")\n",
    "    ckpt_path = f\"checkpoints/snntorch/softLIF/{ep}_acc_{te_acc}.pt\"\n",
    "    torch.save({\"state_dict\": model.state_dict(), \"test_acc\": te_acc}, ckpt_path)\n",
    "print(\"Done. Best test accuracy:\", best_acc * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc8ce1",
   "metadata": {},
   "source": [
    "# Generating spiking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "405be7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def collect_bn_z_stats(relu_model, loader, device, num_batches=50, sample_per_layer=200_000):\n",
    "    relu_model.eval()\n",
    "    samples = {}\n",
    "\n",
    "    def make_hook(name):\n",
    "        def hook(mod, inp, out):\n",
    "            # out is BN output = z (pre-ReLU)\n",
    "            z = out.detach().float().flatten()\n",
    "            # random subsample to keep memory sane\n",
    "            if z.numel() > sample_per_layer:\n",
    "                idx = torch.randint(0, z.numel(), (sample_per_layer,), device=z.device)\n",
    "                z = z[idx]\n",
    "            z = z.cpu()\n",
    "            samples.setdefault(name, []).append(z)\n",
    "        return hook\n",
    "\n",
    "    hooks = []\n",
    "    for name, m in relu_model.named_modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            hooks.append(m.register_forward_hook(make_hook(name)))\n",
    "\n",
    "    # drive a few batches through\n",
    "    for bi, (x, _) in enumerate(loader):\n",
    "        if bi >= num_batches:\n",
    "            break\n",
    "        x = x.to(device)\n",
    "        _ = relu_model(x)\n",
    "\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    # compute percentiles + init params\n",
    "    stats = {}\n",
    "    for name, chunks in samples.items():\n",
    "        z = torch.cat(chunks, dim=0)\n",
    "        q10, q50, q90 = torch.quantile(z, torch.tensor([0.1, 0.5, 0.9]))\n",
    "        dz = (q90 - q10).item()\n",
    "        theta = q50.item()\n",
    "        gain = 4.4 / (dz + 1e-6)         # your rule\n",
    "        gain = float(max(min(gain, 50.0), 0.1))  # clamp to avoid insanity\n",
    "        stats[name] = dict(theta=theta, gain=gain, q10=q10.item(), q50=q50.item(), q90=q90.item())\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "00fc5720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3169246/3030143752.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights_relu = torch.load(\"checkpoints/snntorch/softLIF/17_acc_0.1884.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP32   test acc: 18.84% | loss: 4.2049\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "relu_model = WideResNet(depth=16, widen_factor=10, dropout=0.0, num_classes=100).to(device)\n",
    "weights_relu = torch.load(\"checkpoints/snntorch/softLIF/17_acc_0.1884.pt\")\n",
    "relu_model.load_state_dict(weights_relu[\"state_dict\"], strict=True)  # adapt to your checkpoint\n",
    "relu_loss, relu_acc = evaluate(relu_model, test_loader)\n",
    "print(f\"FP32   test acc: {relu_acc*100:.2f}% | loss: {relu_loss:.4f}\")\n",
    "bn_stats = collect_bn_z_stats(relu_model, train_loader, device, num_batches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "337bfc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['conv1.weight', 'block1.0.act1.theta', 'block1.0.act1.gain', 'block1.0.conv1.weight', 'block1.0.act2.theta', 'block1.0.act2.gain', 'block1.0.conv2.weight', 'block1.1.act1.theta', 'block1.1.act1.gain', 'block1.1.conv1.weight', 'block1.1.act2.theta', 'block1.1.act2.gain', 'block1.1.conv2.weight', 'block2.0.act1.theta', 'block2.0.act1.gain', 'block2.0.conv1.weight', 'block2.0.act2.theta', 'block2.0.act2.gain', 'block2.0.conv2.weight', 'block2.1.act1.theta', 'block2.1.act1.gain', 'block2.1.conv1.weight', 'block2.1.act2.theta', 'block2.1.act2.gain', 'block2.1.conv2.weight', 'block3.0.act1.theta', 'block3.0.act1.gain', 'block3.0.conv1.weight', 'block3.0.act2.theta', 'block3.0.act2.gain', 'block3.0.conv2.weight', 'block3.1.act1.theta', 'block3.1.act1.gain', 'block3.1.conv1.weight', 'block3.1.act2.theta', 'block3.1.act2.gain', 'block3.1.conv2.weight', 'act_out.theta', 'act_out.gain', 'fc.weight', 'fc.bias'], unexpected_keys=['conv1.conv.weight', 'block1.0.conv1.conv.weight', 'block1.0.conv2.conv.weight', 'block1.1.conv1.conv.weight', 'block1.1.conv2.conv.weight', 'block2.0.conv1.conv.weight', 'block2.0.conv2.conv.weight', 'block2.1.conv1.conv.weight', 'block2.1.conv2.conv.weight', 'block3.0.conv1.conv.weight', 'block3.0.conv2.conv.weight', 'block3.1.conv1.conv.weight', 'block3.1.conv2.conv.weight', 'fc.fc.weight', 'fc.fc.bias'])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_model = WideResNet_SoftLIFRate(depth=16, widen_factor=10, dropout=0.0, num_classes=100).to(device)\n",
    "soft_model.load_state_dict(relu_model.state_dict(), strict=False)  # activations are new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "50a7f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softlif_rate01(z, theta, gain, tau_rc=0.02, tau_ref=0.002, eps=1e-4):\n",
    "    z = z.float()\n",
    "    theta = torch.tensor(theta, device=z.device, dtype=torch.float32)\n",
    "    gain  = torch.tensor(gain,  device=z.device, dtype=torch.float32)\n",
    "\n",
    "    u = gain * (z - theta)\n",
    "    Jm1 = F.softplus(u)                 # = J-1\n",
    "    Jm1 = torch.clamp(Jm1, min=eps)\n",
    "    denom = tau_ref + tau_rc * torch.log1p(1.0 / Jm1)\n",
    "    rate = 1.0 / denom\n",
    "    r = rate * tau_ref\n",
    "    return torch.clamp(r, 0.0, 1.0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def solve_gain_for_layer(z10, z90, theta,\n",
    "                         tau_rc=0.02, tau_ref=0.002,\n",
    "                         r_hi=0.90, g_min=0.05, g_max=20.0, iters=30):\n",
    "    \"\"\"\n",
    "    Choose gain so that r(z90) ~= r_hi (keeps layer from saturating too early).\n",
    "    Smaller gain = smoother (more linear), bigger gain = more gate-like.\n",
    "    \"\"\"\n",
    "    z90_t = torch.tensor([z90], device=\"cpu\")\n",
    "\n",
    "    lo, hi = g_min, g_max\n",
    "    for _ in range(iters):\n",
    "        mid = 0.5 * (lo + hi)\n",
    "        r90 = softlif_rate01(z90_t, theta, mid, tau_rc, tau_ref).item()\n",
    "        # if too saturated at z90, gain is too large\n",
    "        if r90 > r_hi:\n",
    "            hi = mid\n",
    "        else:\n",
    "            lo = mid\n",
    "    return 0.5 * (lo + hi)\n",
    "\n",
    "@torch.no_grad()\n",
    "def clamp_softlif_params(model, theta_min=-5.0, theta_max=5.0, gain_min=0.05, gain_max=20.0):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, SoftLIFRate):\n",
    "            m.theta.data.clamp_(theta_min, theta_max)\n",
    "            m.gain.data.clamp_(gain_min, gain_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "6c6e8917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_softlif_from_bn_stats(\n",
    "    soft_model,\n",
    "    bn_stats,\n",
    "    *,\n",
    "    theta_key_prefer=(\"q70\", \"q50\", \"theta\"),  # try q70 -> q50 -> precomputed theta\n",
    "    r_hi=0.90,                                 # keep z90 from saturating too hard\n",
    "    tau_rc=0.02,\n",
    "    tau_ref=0.002,\n",
    "    gain_min=0.05,\n",
    "    gain_max=20.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Initializes SoftLIF params from BN stats but in a way that avoids early saturation.\n",
    "\n",
    "    Expected bn_stats[name] to contain at least q10/q90 and (ideally) q70 or q50.\n",
    "    If your bn_stats already stores 'theta'/'gain', those are used only as fallback.\n",
    "    Requires solve_gain_for_layer(...) to be defined in your notebook.\n",
    "    \"\"\"\n",
    "\n",
    "    def pick_theta(d):\n",
    "        for k in theta_key_prefer:\n",
    "            if k in d:\n",
    "                return float(d[k])\n",
    "        raise KeyError(f\"bn_stats entry missing theta candidates: {theta_key_prefer}\")\n",
    "\n",
    "    def pick_q10_q90(d):\n",
    "        if \"q10\" in d and \"q90\" in d:\n",
    "            return float(d[\"q10\"]), float(d[\"q90\"])\n",
    "        # fallback if older dict uses different keys\n",
    "        if \"z10\" in d and \"z90\" in d:\n",
    "            return float(d[\"z10\"]), float(d[\"z90\"])\n",
    "        raise KeyError(\"bn_stats entry must include q10/q90 (or z10/z90).\")\n",
    "\n",
    "    # map module object -> its qualified name\n",
    "    mod2name = {m: n for n, m in soft_model.named_modules()}\n",
    "\n",
    "    # initialize per-block activations from the BN that feeds them\n",
    "    for m in soft_model.modules():\n",
    "        if isinstance(m, WRNBlock):\n",
    "            # bn1 -> act1\n",
    "            n_bn1 = mod2name[m.bn1]\n",
    "            if n_bn1 in bn_stats:\n",
    "                d = bn_stats[n_bn1]\n",
    "                q10, q90 = pick_q10_q90(d)\n",
    "                theta = pick_theta(d)\n",
    "                gain = solve_gain_for_layer(\n",
    "                    z10=q10, z90=q90, theta=theta,\n",
    "                    tau_rc=tau_rc, tau_ref=tau_ref,\n",
    "                    r_hi=r_hi, g_min=gain_min, g_max=gain_max\n",
    "                )\n",
    "                m.act1.theta.data.fill_(theta)\n",
    "                m.act1.gain.data.fill_(gain)\n",
    "\n",
    "            # bn2 -> act2\n",
    "            n_bn2 = mod2name[m.bn2]\n",
    "            if n_bn2 in bn_stats:\n",
    "                d = bn_stats[n_bn2]\n",
    "                q10, q90 = pick_q10_q90(d)\n",
    "                theta = pick_theta(d)\n",
    "                gain = solve_gain_for_layer(\n",
    "                    z10=q10, z90=q90, theta=theta,\n",
    "                    tau_rc=tau_rc, tau_ref=tau_ref,\n",
    "                    r_hi=r_hi, g_min=gain_min, g_max=gain_max\n",
    "                )\n",
    "                m.act2.theta.data.fill_(theta)\n",
    "                m.act2.gain.data.fill_(gain)\n",
    "\n",
    "    # final BN -> final activation\n",
    "    n_final_bn = mod2name[soft_model.bn]\n",
    "    if n_final_bn in bn_stats:\n",
    "        d = bn_stats[n_final_bn]\n",
    "        q10, q90 = pick_q10_q90(d)\n",
    "        theta = pick_theta(d)\n",
    "        gain = solve_gain_for_layer(\n",
    "            z10=q10, z90=q90, theta=theta,\n",
    "            tau_rc=tau_rc, tau_ref=tau_ref,\n",
    "            r_hi=r_hi, g_min=gain_min, g_max=gain_max\n",
    "        )\n",
    "        soft_model.act_out.theta.data.fill_(theta)\n",
    "        soft_model.act_out.gain.data.fill_(gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "df964e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_softlif_from_bn_stats(soft_model, bn_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "a9fb42b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_bn_eval(m):\n",
    "    # freezes BN running mean/var updates\n",
    "    for mod in m.modules():\n",
    "        if isinstance(mod, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
    "            mod.eval()\n",
    "\n",
    "def get_softlif_params(m):\n",
    "    # theta/gain only\n",
    "    params = []\n",
    "    for mod in m.modules():\n",
    "        if isinstance(mod, SoftLIFRate):\n",
    "            params.append(mod.theta)\n",
    "            params.append(mod.gain)\n",
    "    return params\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch(model, loader, device, criterion=None):\n",
    "    model.eval()\n",
    "    tot, correct, loss_sum = 0, 0, 0.0\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        if criterion is not None:\n",
    "            loss_sum += criterion(logits, y).item() * y.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        tot += y.numel()\n",
    "    acc = 100.0 * correct / tot\n",
    "    loss = (loss_sum / tot) if (criterion is not None) else None\n",
    "    return acc, loss\n",
    "\n",
    "def train_epoch(model, loader, device, optimizer, criterion, freeze_bn=False, grad_clip=None):\n",
    "    model.train()\n",
    "    if freeze_bn:\n",
    "        set_bn_eval(model)\n",
    "\n",
    "    tot, correct, loss_sum = 0, 0, 0.0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "\n",
    "        if grad_clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum += loss.item() * y.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        tot += y.numel()\n",
    "\n",
    "    return 100.0 * correct / tot, loss_sum / tot\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=8, shuffle=True,\n",
    "                          num_workers=2, pin_memory=True)\n",
    "\n",
    "theta_gain_only_epochs = 0\n",
    "total_finetune_epochs  = 1   # includes the first 2 epochs\n",
    "lr_theta_gain = 3e-4\n",
    "lr_full = 2e-4\n",
    "weight_decay = 5e-4\n",
    "grad_clip = None  # e.g., 1.0 if unstable\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ---- Phase 1: freeze all except theta/gain ----\n",
    "def is_softlif_param(name):\n",
    "    return (\".theta\" in name) or (\".gain\" in name)\n",
    "for p in soft_model.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in get_softlif_params(soft_model):\n",
    "    p.requires_grad = True\n",
    "\n",
    "opt1 = torch.optim.AdamW(\n",
    "    get_softlif_params(soft_model),\n",
    "    lr=lr_theta_gain,\n",
    "    weight_decay=0.0\n",
    ")\n",
    "\n",
    "for epoch in range(1, theta_gain_only_epochs + 1):\n",
    "    tr_acc, tr_loss = train_epoch(\n",
    "        soft_model, train_loader, device, opt1, criterion,\n",
    "        freeze_bn=True,            # IMPORTANT in phase 1\n",
    "        grad_clip=grad_clip\n",
    "    )\n",
    "    te_acc, te_loss = eval_epoch(soft_model, test_loader, device, criterion)\n",
    "    print(f\"[Phase1 {epoch}/{theta_gain_only_epochs}] \"\n",
    "          f\"train acc={tr_acc:.2f} loss={tr_loss:.4f} | \"\n",
    "          f\"test acc={te_acc:.2f} loss={te_loss:.4f}\")\n",
    "\n",
    "# ---- Phase 2: unfreeze all, small LR ----\n",
    "for p in soft_model.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "decay, no_decay = [], []\n",
    "for n, p in soft_model.named_parameters():\n",
    "    if not p.requires_grad:\n",
    "        continue\n",
    "    if is_softlif_param(n) or n.endswith(\".bias\") or \"bn\" in n.lower():\n",
    "        no_decay.append(p)\n",
    "    else:\n",
    "        decay.append(p)\n",
    "\n",
    "opt2 = torch.optim.SGD(\n",
    "    [\n",
    "        {\"params\": decay, \"weight_decay\": 5e-4},\n",
    "        {\"params\": no_decay, \"weight_decay\": 0.0},\n",
    "    ],\n",
    "    lr=lr_full, momentum=0.9, nesterov=True\n",
    ")\n",
    "\n",
    "# optional scheduler (safe default)\n",
    "sched2 = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    opt2, T_max=max(1, total_finetune_epochs - theta_gain_only_epochs)\n",
    ")\n",
    "\n",
    "# for epoch in range(theta_gain_only_epochs + 1, total_finetune_epochs + 1):\n",
    "#     tr_acc, tr_loss = train_epoch(\n",
    "#         soft_model, train_loader, device, opt2, criterion,\n",
    "#         freeze_bn=False,           # BN can adapt again in phase 2\n",
    "#         grad_clip=grad_clip\n",
    "#     )\n",
    "#     te_acc, te_loss = eval_epoch(soft_model, test_loader, device, criterion)\n",
    "#     sched2.step()\n",
    "#     torch.save({\"state_dict\": soft_model.state_dict(), \"test_acc\": te_acc}, f\"checkpoints/snntorch/softLIF/finetune_epoch_{epoch}.pt\")\n",
    "#     print(f\"[Phase2 {epoch}/{total_finetune_epochs}] \"\n",
    "#           f\"train acc={tr_acc:.2f} loss={tr_loss:.4f} | \"\n",
    "#           f\"test acc={te_acc:.2f} loss={te_loss:.4f} | \"\n",
    "#           f\"lr={opt2.param_groups[0]['lr']:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "b84c1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_load = torch.load(\"checkpoints/snntorch/softLIF/finetune_epoch_63.pt\")\n",
    "# soft_model.load_state_dict(weights_load[\"state_dict\"], strict=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "2be4fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\"state_dict\": soft_model.state_dict(), \"test_acc\": te_acc}, f\"checkpoints/snntorch/softLIF/finetune_epoch_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df30720",
   "metadata": {},
   "source": [
    "# Hardware-realistic inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae1de9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "ee581d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_weight, max_weight = -0.7, 0.7\n",
    "num_weight_levels = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "0c9e4cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_encode(x, input_scale=1.0, clamp01=False):\n",
    "    \"\"\"\n",
    "    x: (B,3,H,W), can be negative (after Normalize)\n",
    "    returns: (B,6,H,W) = [x_pos, x_neg] where x = x_pos - x_neg\n",
    "\n",
    "    If clamp01=True -> enforce duty-cycle limit [0,1] (hardware-like) but introduces saturation.\n",
    "    \"\"\"\n",
    "    x = x / float(input_scale)\n",
    "    x_pos = torch.clamp(x, min=0.0)\n",
    "    x_neg = torch.clamp(-x, min=0.0)\n",
    "    if clamp01:\n",
    "        x_pos = x_pos.clamp(0.0, 1.0)\n",
    "        x_neg = x_neg.clamp(0.0, 1.0)\n",
    "    return torch.cat([x_pos, x_neg], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "af468a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_input_scale(loader, device=\"cuda\", batches=50, q=0.99):\n",
    "    vals = []\n",
    "    for i, (x, _) in enumerate(loader):\n",
    "        if i >= batches: break\n",
    "        x = x.to(device)\n",
    "        vals.append(x.abs().flatten())\n",
    "    v = torch.cat(vals)\n",
    "    return float(torch.quantile(v, torch.tensor(q, device=v.device)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "47e1be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def convert_softlif_to_diff_in(soft_model_3ch, input_scale=1.0, device=\"cuda\"):\n",
    "    # 1) build 6-channel model\n",
    "    diff_model = WideResNet_SoftLIFRate(\n",
    "        depth=16, widen_factor=10, dropout=0.0, num_classes=100,\n",
    "        in_channels=6\n",
    "    ).to(device)\n",
    "\n",
    "    # 2) load all weights EXCEPT conv1\n",
    "    sd = soft_model_3ch.state_dict()\n",
    "    sd = {k: v for k, v in sd.items() if k != \"conv1.conv.weight\"}  # drop mismatched tensor\n",
    "    incompatible = diff_model.load_state_dict(sd, strict=False)\n",
    "\n",
    "    # 3) set conv1 as [W, -W] and compensate scaling\n",
    "    W3 = soft_model_3ch.conv1.conv.weight.data  # (out,3,k,k)\n",
    "    W6 = torch.cat([W3, -W3], dim=1)            # (out,6,k,k)\n",
    "    diff_model.conv1.conv.weight.data.copy_(W6 * float(input_scale))\n",
    "\n",
    "    return diff_model, incompatible.missing_keys, incompatible.unexpected_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "de003cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_model = WideResNet_SoftLIFRate(\n",
    "    depth=16, widen_factor=10, dropout=0.0, num_classes=100,\n",
    "    in_channels=6\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "932a922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SCALE = estimate_input_scale(train_loader, device=device, batches=50, q=0.99)\n",
    "# diff_model, missing, unexpected = convert_softlif_to_diff_in(soft_model, input_scale=INPUT_SCALE, device=device)\n",
    "# print(\"missing:\", missing)\n",
    "# print(\"unexpected:\", unexpected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "799edec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_diff_model(diff_model, loader, input_scale, clamp01, device=\"cuda\"):\n",
    "    diff_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0.0\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        x6 = diff_encode(x, input_scale=input_scale, clamp01=clamp01)\n",
    "        logits = diff_model(x6)\n",
    "\n",
    "        loss = ce(logits, y)\n",
    "        loss_sum += float(loss.item()) * y.numel()\n",
    "\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += int((pred == y).sum().item())\n",
    "        total += int(y.numel())\n",
    "\n",
    "    return 100.0 * correct / total, loss_sum / total\n",
    "\n",
    "\n",
    "def train_diff_model(\n",
    "    diff_model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    input_scale,\n",
    "    epochs=10,\n",
    "    lr=1e-4,\n",
    "    weight_decay=5e-4,\n",
    "    clamp01=False,\n",
    "    device=\"cuda\",\n",
    "    use_amp=True,\n",
    "    grad_clip=0.0,\n",
    "):\n",
    "    diff_model.to(device)\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    # optimizer: AdamW is stable for fine-tuning\n",
    "    opt = torch.optim.AdamW(diff_model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # simple cosine schedule (optional but good)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
    "\n",
    "    scaler = GradScaler(device=device, enabled=use_amp)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        diff_model.train()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        loss_sum = 0.0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "\n",
    "            x6 = diff_encode(x, input_scale=input_scale, clamp01=clamp01)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast(device_type=device.type, enabled=use_amp):\n",
    "                logits = diff_model(x6)\n",
    "                loss = ce(logits, y)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if grad_clip and grad_clip > 0:\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(diff_model.parameters(), grad_clip)\n",
    "\n",
    "            scaler.step(opt)\n",
    "            clamp_weights_(diff_model, min_weight, max_weight)\n",
    "            scaler.update()\n",
    "\n",
    "            loss_sum += float(loss.item()) * y.numel()\n",
    "            pred = logits.argmax(dim=1)\n",
    "            correct += int((pred == y).sum().item())\n",
    "            total += int(y.numel())\n",
    "\n",
    "        sched.step()\n",
    "        opt.step()\n",
    "\n",
    "        tr_acc = 100.0 * correct / total\n",
    "        tr_loss = loss_sum / total\n",
    "        te_acc, te_loss = evaluate_diff_model(diff_model, test_loader, input_scale, clamp01, device=device)\n",
    "\n",
    "        torch.save({\"state_dict\": diff_model.state_dict(), \"test_acc\": te_acc}, f\"checkpoints/QAT/epoch_{epoch}_acc_{te_acc:.4f}.pt\")\n",
    "        print(f\"[{epoch:02d}/{epochs}] \"\n",
    "              f\"train acc={tr_acc:.2f} loss={tr_loss:.4f} | \"\n",
    "              f\"test acc={te_acc:.2f} loss={te_loss:.4f} | \"\n",
    "              f\"lr={opt.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "    return diff_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "6b7cb0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sanity: diff input shape\n",
    "# x, y = next(iter(train_loader))\n",
    "# x6 = diff_encode(x.to(device), INPUT_SCALE, clamp01=False)\n",
    "# print(\"x:\", x.shape, \"x6:\", x6.shape)  # should be (B,3,H,W) -> (B,6,H,W)\n",
    "\n",
    "# # sanity: forward works\n",
    "# diff_model.eval()\n",
    "# with torch.no_grad():\n",
    "#     logits = diff_model(x6)\n",
    "# print(\"logits:\", logits.shape)  # (B, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "5a56464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# err = (x.to(device) / INPUT_SCALE - (x6[:, :3] - x6[:, 3:])).abs().max().item()\n",
    "# print(\"max reconstruction error:\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "969f377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft_model.eval()\n",
    "# diff_model.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     y_old = soft_model.conv1(x.to(device))\n",
    "#     y_new = diff_model.conv1(x6)\n",
    "\n",
    "# print(\"conv1 max abs diff:\", (y_old - y_new).abs().max().item())\n",
    "# print(\"conv1 mean abs diff:\", (y_old - y_new).abs().mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "4cc7fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, _ = next(iter(train_loader))\n",
    "# x = x.to(device)\n",
    "# x6 = diff_encode(x, input_scale=INPUT_SCALE, clamp01=False)\n",
    "# print(\"x6 min/max (no clamp):\", x6.min().item(), x6.max().item())\n",
    "# x6c = diff_encode(x, input_scale=INPUT_SCALE, clamp01=True)\n",
    "# print(\"x6 min/max (clamp01=True):\", x6c.min().item(), x6c.max().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "ff5be23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/400] train acc=7.51 loss=4.0393 | test acc=11.06 loss=3.7404 | lr=1.00e-04\n",
      "[02/400] train acc=10.22 loss=3.8539 | test acc=13.91 loss=3.5578 | lr=1.00e-04\n",
      "[03/400] train acc=13.05 loss=3.6620 | test acc=15.64 loss=3.4967 | lr=1.00e-04\n",
      "[04/400] train acc=15.76 loss=3.4885 | test acc=21.50 loss=3.0911 | lr=1.00e-04\n",
      "[05/400] train acc=19.10 loss=3.3047 | test acc=27.00 loss=2.7888 | lr=1.00e-04\n",
      "[06/400] train acc=22.22 loss=3.1329 | test acc=28.17 loss=2.7471 | lr=9.99e-05\n",
      "[07/400] train acc=25.62 loss=2.9584 | test acc=35.79 loss=2.4060 | lr=9.99e-05\n",
      "[08/400] train acc=28.50 loss=2.8026 | test acc=38.63 loss=2.2624 | lr=9.99e-05\n",
      "[09/400] train acc=31.45 loss=2.6787 | test acc=40.54 loss=2.1712 | lr=9.99e-05\n",
      "[10/400] train acc=34.14 loss=2.5489 | test acc=43.93 loss=2.0580 | lr=9.98e-05\n",
      "[11/400] train acc=36.61 loss=2.4338 | test acc=46.95 loss=1.9279 | lr=9.98e-05\n",
      "[12/400] train acc=38.98 loss=2.3307 | test acc=48.46 loss=1.8619 | lr=9.98e-05\n",
      "[13/400] train acc=41.24 loss=2.2237 | test acc=51.19 loss=1.7357 | lr=9.97e-05\n",
      "[14/400] train acc=43.15 loss=2.1390 | test acc=52.68 loss=1.7077 | lr=9.97e-05\n",
      "[15/400] train acc=45.16 loss=2.0585 | test acc=54.18 loss=1.6413 | lr=9.97e-05\n",
      "[16/400] train acc=47.16 loss=1.9776 | test acc=57.20 loss=1.5104 | lr=9.96e-05\n",
      "[17/400] train acc=48.67 loss=1.9024 | test acc=57.22 loss=1.5038 | lr=9.96e-05\n",
      "[18/400] train acc=50.36 loss=1.8388 | test acc=58.66 loss=1.4597 | lr=9.95e-05\n",
      "[19/400] train acc=51.85 loss=1.7751 | test acc=60.64 loss=1.3972 | lr=9.94e-05\n",
      "[20/400] train acc=53.42 loss=1.7078 | test acc=59.74 loss=1.3968 | lr=9.94e-05\n",
      "[21/400] train acc=54.80 loss=1.6548 | test acc=62.14 loss=1.3334 | lr=9.93e-05\n",
      "[22/400] train acc=55.96 loss=1.6000 | test acc=62.52 loss=1.3267 | lr=9.93e-05\n",
      "[23/400] train acc=57.57 loss=1.5463 | test acc=63.32 loss=1.2823 | lr=9.92e-05\n",
      "[24/400] train acc=58.20 loss=1.5122 | test acc=63.38 loss=1.2897 | lr=9.91e-05\n",
      "[25/400] train acc=59.53 loss=1.4613 | test acc=64.50 loss=1.2362 | lr=9.90e-05\n",
      "[26/400] train acc=60.38 loss=1.4168 | test acc=65.64 loss=1.2069 | lr=9.90e-05\n",
      "[27/400] train acc=61.57 loss=1.3723 | test acc=66.06 loss=1.2210 | lr=9.89e-05\n",
      "[28/400] train acc=62.70 loss=1.3403 | test acc=65.72 loss=1.2073 | lr=9.88e-05\n",
      "[29/400] train acc=63.76 loss=1.2868 | test acc=66.83 loss=1.1822 | lr=9.87e-05\n",
      "[30/400] train acc=64.68 loss=1.2652 | test acc=68.00 loss=1.1579 | lr=9.86e-05\n",
      "[31/400] train acc=65.34 loss=1.2318 | test acc=67.76 loss=1.1501 | lr=9.85e-05\n",
      "[32/400] train acc=66.37 loss=1.2010 | test acc=67.43 loss=1.1832 | lr=9.84e-05\n",
      "[33/400] train acc=66.87 loss=1.1715 | test acc=67.90 loss=1.1392 | lr=9.83e-05\n",
      "[34/400] train acc=67.98 loss=1.1391 | test acc=68.40 loss=1.1180 | lr=9.82e-05\n",
      "[35/400] train acc=68.83 loss=1.1048 | test acc=69.49 loss=1.1071 | lr=9.81e-05\n",
      "[36/400] train acc=69.14 loss=1.0778 | test acc=70.08 loss=1.0857 | lr=9.80e-05\n",
      "[37/400] train acc=70.23 loss=1.0498 | test acc=69.75 loss=1.0892 | lr=9.79e-05\n",
      "[38/400] train acc=70.77 loss=1.0269 | test acc=69.68 loss=1.1087 | lr=9.78e-05\n",
      "[39/400] train acc=71.74 loss=0.9964 | test acc=70.44 loss=1.0856 | lr=9.77e-05\n",
      "[40/400] train acc=71.94 loss=0.9806 | test acc=69.93 loss=1.1012 | lr=9.76e-05\n",
      "[41/400] train acc=72.76 loss=0.9527 | test acc=70.77 loss=1.0674 | lr=9.74e-05\n",
      "[42/400] train acc=73.22 loss=0.9322 | test acc=70.67 loss=1.0908 | lr=9.73e-05\n",
      "[43/400] train acc=73.98 loss=0.8992 | test acc=71.03 loss=1.0782 | lr=9.72e-05\n",
      "[44/400] train acc=74.51 loss=0.8789 | test acc=71.41 loss=1.0739 | lr=9.70e-05\n",
      "[45/400] train acc=75.23 loss=0.8638 | test acc=71.33 loss=1.0967 | lr=9.69e-05\n",
      "[46/400] train acc=75.48 loss=0.8442 | test acc=71.72 loss=1.0580 | lr=9.68e-05\n",
      "[47/400] train acc=76.26 loss=0.8206 | test acc=71.64 loss=1.0591 | lr=9.66e-05\n",
      "[48/400] train acc=76.57 loss=0.8041 | test acc=70.78 loss=1.1214 | lr=9.65e-05\n",
      "[49/400] train acc=76.91 loss=0.7952 | test acc=71.47 loss=1.0808 | lr=9.63e-05\n",
      "[50/400] train acc=77.43 loss=0.7765 | test acc=72.02 loss=1.0759 | lr=9.62e-05\n",
      "[51/400] train acc=77.87 loss=0.7596 | test acc=72.29 loss=1.0699 | lr=9.60e-05\n",
      "[52/400] train acc=78.73 loss=0.7335 | test acc=72.43 loss=1.0987 | lr=9.59e-05\n",
      "[53/400] train acc=78.98 loss=0.7220 | test acc=71.58 loss=1.1266 | lr=9.57e-05\n",
      "[54/400] train acc=79.27 loss=0.7043 | test acc=72.88 loss=1.0664 | lr=9.56e-05\n",
      "[55/400] train acc=79.49 loss=0.6996 | test acc=72.42 loss=1.0984 | lr=9.54e-05\n",
      "[56/400] train acc=80.14 loss=0.6850 | test acc=72.80 loss=1.0944 | lr=9.52e-05\n",
      "[57/400] train acc=80.30 loss=0.6713 | test acc=72.50 loss=1.0878 | lr=9.51e-05\n",
      "[58/400] train acc=80.74 loss=0.6563 | test acc=72.53 loss=1.1078 | lr=9.49e-05\n",
      "[59/400] train acc=81.14 loss=0.6448 | test acc=72.65 loss=1.1156 | lr=9.47e-05\n",
      "[60/400] train acc=81.54 loss=0.6238 | test acc=72.83 loss=1.1134 | lr=9.46e-05\n",
      "[61/400] train acc=82.31 loss=0.6079 | test acc=73.51 loss=1.0971 | lr=9.44e-05\n",
      "[62/400] train acc=82.56 loss=0.6014 | test acc=72.71 loss=1.1468 | lr=9.42e-05\n",
      "[63/400] train acc=82.68 loss=0.5934 | test acc=73.53 loss=1.0967 | lr=9.40e-05\n",
      "[64/400] train acc=83.09 loss=0.5750 | test acc=73.40 loss=1.1116 | lr=9.38e-05\n",
      "[65/400] train acc=83.14 loss=0.5724 | test acc=73.91 loss=1.0886 | lr=9.36e-05\n",
      "[66/400] train acc=83.46 loss=0.5607 | test acc=73.10 loss=1.1507 | lr=9.34e-05\n",
      "[67/400] train acc=83.65 loss=0.5566 | test acc=72.84 loss=1.1460 | lr=9.32e-05\n",
      "[68/400] train acc=84.14 loss=0.5390 | test acc=73.44 loss=1.1194 | lr=9.30e-05\n",
      "[69/400] train acc=84.54 loss=0.5286 | test acc=73.33 loss=1.1343 | lr=9.28e-05\n",
      "[70/400] train acc=84.58 loss=0.5216 | test acc=72.96 loss=1.1591 | lr=9.26e-05\n",
      "[71/400] train acc=85.20 loss=0.5065 | test acc=73.05 loss=1.1543 | lr=9.24e-05\n",
      "[72/400] train acc=85.19 loss=0.5015 | test acc=73.21 loss=1.1639 | lr=9.22e-05\n",
      "[73/400] train acc=85.39 loss=0.4981 | test acc=73.63 loss=1.1482 | lr=9.20e-05\n",
      "[74/400] train acc=85.76 loss=0.4781 | test acc=73.94 loss=1.1484 | lr=9.18e-05\n",
      "[75/400] train acc=85.96 loss=0.4806 | test acc=73.64 loss=1.1633 | lr=9.16e-05\n",
      "[76/400] train acc=86.25 loss=0.4705 | test acc=73.52 loss=1.1568 | lr=9.14e-05\n",
      "[77/400] train acc=86.30 loss=0.4610 | test acc=73.67 loss=1.1578 | lr=9.11e-05\n",
      "[78/400] train acc=86.64 loss=0.4524 | test acc=73.47 loss=1.1786 | lr=9.09e-05\n",
      "[79/400] train acc=86.72 loss=0.4534 | test acc=74.06 loss=1.1662 | lr=9.07e-05\n",
      "[80/400] train acc=86.94 loss=0.4417 | test acc=72.75 loss=1.2232 | lr=9.05e-05\n",
      "[81/400] train acc=87.50 loss=0.4285 | test acc=73.85 loss=1.2016 | lr=9.02e-05\n",
      "[82/400] train acc=87.26 loss=0.4372 | test acc=73.84 loss=1.1861 | lr=9.00e-05\n",
      "[83/400] train acc=87.71 loss=0.4175 | test acc=73.60 loss=1.2084 | lr=8.97e-05\n",
      "[84/400] train acc=87.66 loss=0.4155 | test acc=73.79 loss=1.2447 | lr=8.95e-05\n",
      "[85/400] train acc=87.97 loss=0.4054 | test acc=73.54 loss=1.2176 | lr=8.93e-05\n",
      "[86/400] train acc=88.20 loss=0.3955 | test acc=74.72 loss=1.1945 | lr=8.90e-05\n",
      "[87/400] train acc=88.34 loss=0.3915 | test acc=73.69 loss=1.2015 | lr=8.88e-05\n",
      "[88/400] train acc=88.54 loss=0.3928 | test acc=73.78 loss=1.2339 | lr=8.85e-05\n",
      "[89/400] train acc=88.76 loss=0.3827 | test acc=74.13 loss=1.2048 | lr=8.83e-05\n",
      "[90/400] train acc=88.81 loss=0.3795 | test acc=73.64 loss=1.2437 | lr=8.80e-05\n",
      "[91/400] train acc=88.89 loss=0.3724 | test acc=74.09 loss=1.2261 | lr=8.78e-05\n",
      "[92/400] train acc=89.14 loss=0.3683 | test acc=73.93 loss=1.2319 | lr=8.75e-05\n",
      "[93/400] train acc=89.41 loss=0.3617 | test acc=74.34 loss=1.2508 | lr=8.72e-05\n",
      "[94/400] train acc=89.36 loss=0.3569 | test acc=74.41 loss=1.2210 | lr=8.70e-05\n",
      "[95/400] train acc=89.53 loss=0.3541 | test acc=74.46 loss=1.2454 | lr=8.67e-05\n",
      "[96/400] train acc=89.84 loss=0.3426 | test acc=73.83 loss=1.2920 | lr=8.64e-05\n",
      "[97/400] train acc=89.83 loss=0.3457 | test acc=74.09 loss=1.2570 | lr=8.62e-05\n",
      "[98/400] train acc=90.08 loss=0.3422 | test acc=73.59 loss=1.2523 | lr=8.59e-05\n",
      "[99/400] train acc=90.21 loss=0.3383 | test acc=73.85 loss=1.2835 | lr=8.56e-05\n",
      "[100/400] train acc=89.95 loss=0.3408 | test acc=74.20 loss=1.2747 | lr=8.54e-05\n",
      "[101/400] train acc=90.39 loss=0.3270 | test acc=74.44 loss=1.2813 | lr=8.51e-05\n",
      "[102/400] train acc=90.52 loss=0.3190 | test acc=74.36 loss=1.2551 | lr=8.48e-05\n",
      "[103/400] train acc=90.86 loss=0.3151 | test acc=74.21 loss=1.2754 | lr=8.45e-05\n",
      "[104/400] train acc=90.77 loss=0.3175 | test acc=73.62 loss=1.3201 | lr=8.42e-05\n",
      "[105/400] train acc=90.88 loss=0.3132 | test acc=74.13 loss=1.2880 | lr=8.39e-05\n",
      "[106/400] train acc=90.92 loss=0.3110 | test acc=74.21 loss=1.2899 | lr=8.37e-05\n",
      "[107/400] train acc=91.20 loss=0.3014 | test acc=73.96 loss=1.3189 | lr=8.34e-05\n",
      "[108/400] train acc=91.21 loss=0.2991 | test acc=74.26 loss=1.3197 | lr=8.31e-05\n",
      "[109/400] train acc=91.56 loss=0.2904 | test acc=73.58 loss=1.3339 | lr=8.28e-05\n",
      "[110/400] train acc=91.37 loss=0.2931 | test acc=74.27 loss=1.3270 | lr=8.25e-05\n",
      "[111/400] train acc=91.72 loss=0.2872 | test acc=74.22 loss=1.2997 | lr=8.22e-05\n",
      "[112/400] train acc=91.50 loss=0.2850 | test acc=74.74 loss=1.2857 | lr=8.19e-05\n",
      "[113/400] train acc=91.84 loss=0.2797 | test acc=74.82 loss=1.3024 | lr=8.16e-05\n",
      "[114/400] train acc=91.83 loss=0.2822 | test acc=74.40 loss=1.3244 | lr=8.13e-05\n",
      "[115/400] train acc=91.71 loss=0.2810 | test acc=73.80 loss=1.3879 | lr=8.10e-05\n",
      "[116/400] train acc=91.87 loss=0.2774 | test acc=74.21 loss=1.3449 | lr=8.06e-05\n",
      "[117/400] train acc=92.21 loss=0.2686 | test acc=74.44 loss=1.3491 | lr=8.03e-05\n",
      "[118/400] train acc=92.27 loss=0.2656 | test acc=74.09 loss=1.3723 | lr=8.00e-05\n",
      "[119/400] train acc=92.25 loss=0.2609 | test acc=74.42 loss=1.3509 | lr=7.97e-05\n",
      "[120/400] train acc=92.46 loss=0.2585 | test acc=74.18 loss=1.3395 | lr=7.94e-05\n",
      "[121/400] train acc=92.33 loss=0.2590 | test acc=75.08 loss=1.3111 | lr=7.91e-05\n",
      "[122/400] train acc=92.51 loss=0.2562 | test acc=74.29 loss=1.3731 | lr=7.88e-05\n",
      "[123/400] train acc=92.46 loss=0.2561 | test acc=74.61 loss=1.3507 | lr=7.84e-05\n",
      "[124/400] train acc=92.75 loss=0.2465 | test acc=74.75 loss=1.3484 | lr=7.81e-05\n",
      "[125/400] train acc=92.66 loss=0.2478 | test acc=74.52 loss=1.3760 | lr=7.78e-05\n",
      "[126/400] train acc=92.91 loss=0.2425 | test acc=74.75 loss=1.3947 | lr=7.75e-05\n",
      "[127/400] train acc=92.88 loss=0.2447 | test acc=74.09 loss=1.4264 | lr=7.71e-05\n",
      "[128/400] train acc=93.04 loss=0.2370 | test acc=74.07 loss=1.4202 | lr=7.68e-05\n",
      "[129/400] train acc=93.10 loss=0.2346 | test acc=74.75 loss=1.3658 | lr=7.65e-05\n",
      "[130/400] train acc=93.15 loss=0.2353 | test acc=74.32 loss=1.3621 | lr=7.61e-05\n",
      "[131/400] train acc=93.27 loss=0.2271 | test acc=74.65 loss=1.3751 | lr=7.58e-05\n",
      "[132/400] train acc=93.37 loss=0.2275 | test acc=74.68 loss=1.4000 | lr=7.55e-05\n",
      "[133/400] train acc=93.25 loss=0.2358 | test acc=74.44 loss=1.4434 | lr=7.51e-05\n",
      "[134/400] train acc=93.53 loss=0.2258 | test acc=74.30 loss=1.3959 | lr=7.48e-05\n",
      "[135/400] train acc=93.61 loss=0.2259 | test acc=74.97 loss=1.3744 | lr=7.44e-05\n",
      "[136/400] train acc=93.52 loss=0.2241 | test acc=74.53 loss=1.3952 | lr=7.41e-05\n",
      "[137/400] train acc=93.84 loss=0.2147 | test acc=74.50 loss=1.3915 | lr=7.37e-05\n",
      "[138/400] train acc=93.76 loss=0.2166 | test acc=74.80 loss=1.3750 | lr=7.34e-05\n",
      "[139/400] train acc=93.95 loss=0.2103 | test acc=75.11 loss=1.3704 | lr=7.30e-05\n",
      "[140/400] train acc=93.73 loss=0.2127 | test acc=74.82 loss=1.4136 | lr=7.27e-05\n",
      "[141/400] train acc=93.84 loss=0.2058 | test acc=75.14 loss=1.4047 | lr=7.23e-05\n",
      "[142/400] train acc=94.00 loss=0.2034 | test acc=75.08 loss=1.3906 | lr=7.20e-05\n",
      "[143/400] train acc=93.98 loss=0.2088 | test acc=74.40 loss=1.4399 | lr=7.16e-05\n",
      "[144/400] train acc=94.18 loss=0.1999 | test acc=75.17 loss=1.3858 | lr=7.13e-05\n",
      "[145/400] train acc=94.18 loss=0.1986 | test acc=75.07 loss=1.4108 | lr=7.09e-05\n",
      "[146/400] train acc=94.08 loss=0.2000 | test acc=74.72 loss=1.4086 | lr=7.06e-05\n",
      "[147/400] train acc=94.27 loss=0.1957 | test acc=75.48 loss=1.4237 | lr=7.02e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[370]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m diff_model = \u001b[43mtrain_diff_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiff_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mINPUT_SCALE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# fine-tune small\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclamp01\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# start here\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_clip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[369]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mtrain_diff_model\u001b[39m\u001b[34m(diff_model, train_loader, test_loader, input_scale, epochs, lr, weight_decay, clamp01, device, use_amp, grad_clip)\u001b[39m\n\u001b[32m     74\u001b[39m     scaler.unscale_(opt)\n\u001b[32m     75\u001b[39m     torch.nn.utils.clip_grad_norm_(diff_model.parameters(), grad_clip)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m clamp_weights_(diff_model, min_weight, max_weight)\n\u001b[32m     79\u001b[39m scaler.update()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rezvan-env/lib/python3.11/site-packages/torch/amp/grad_scaler.py:457\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    451\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    454\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    455\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rezvan-env/lib/python3.11/site-packages/torch/amp/grad_scaler.py:351\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    345\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     **kwargs: Any,\n\u001b[32m    349\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    350\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v.item() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    352\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rezvan-env/lib/python3.11/site-packages/torch/amp/grad_scaler.py:351\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    345\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     **kwargs: Any,\n\u001b[32m    349\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    350\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    352\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "diff_model = train_diff_model(\n",
    "    diff_model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    input_scale=INPUT_SCALE,\n",
    "    epochs=400,\n",
    "    lr=1e-4,            # fine-tune small\n",
    "    weight_decay=5e-4,\n",
    "    clamp01=False,      # start here\n",
    "    device=device,\n",
    "    use_amp=True,\n",
    "    grad_clip=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd4791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\"state_dict\": diff_model.state_dict(), \"test_acc\": te_acc}, f\"checkpoints/snntorch/diffEncoding/epoch_{epoch}_acc_{te_acc:.4f}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84143385",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_model = train_diff_model(\n",
    "    diff_model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    input_scale=INPUT_SCALE,\n",
    "    epochs=10,\n",
    "    lr=5e-5,\n",
    "    weight_decay=5e-4,\n",
    "    clamp01=True,\n",
    "    device=device,\n",
    "    use_amp=True,\n",
    "    grad_clip=1.0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bbf070",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_load = torch.load(\"checkpoints/QAT/epoch_269_acc_77.2300.pt\")\n",
    "diff_model.load_state_dict(weights_load[\"state_dict\"], strict=False)\n",
    "fp_acc , fp_loss= evaluate_diff_model(diff_model, test_loader, INPUT_SCALE, False, device=device)\n",
    "print(f\"FP32   test acc: {fp_acc:.2f}% | loss: {fp_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa514c3e",
   "metadata": {},
   "source": [
    "## Noisy Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "576ffda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3169246/1108632369.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt =  torch.load(\"checkpoints/QAT/epoch_269_acc_77.2300.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP32   test acc: 76.65% | loss: 1.4955\n"
     ]
    }
   ],
   "source": [
    "ckpt =  torch.load(\"checkpoints/QAT/epoch_269_acc_77.2300.pt\")\n",
    "model_fp = WideResNet_SoftLIFRate(\n",
    "    depth=16, widen_factor=10, dropout=0.0, num_classes=100, in_channels=6\n",
    ").to(device)\n",
    "model_fp.load_state_dict(ckpt[\"state_dict\"], strict=True)\n",
    "INPUT_SCALE = estimate_input_scale(train_loader, device=device, batches=50, q=0.99)\n",
    "fp_acc, fp_loss = evaluate_diff_model(model_fp, test_loader, INPUT_SCALE, False, device=device)\n",
    "print(f\"FP32   test acc: {fp_acc:.2f}% | loss: {fp_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "d306ee9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quant bounds: min_weight=-0.7, max_weight=0.699776, num_weight_levels=24\n"
     ]
    }
   ],
   "source": [
    "def iter_named_weight_tensors(m: nn.Module, include_bias: bool = True):\n",
    "    for mod_name, mod in m.named_modules():\n",
    "        if isinstance(mod, (nn.Conv2d, nn.Linear)):\n",
    "            if getattr(mod, \"weight\", None) is not None:\n",
    "                yield f\"{mod_name}.weight\", mod.weight\n",
    "            if include_bias and getattr(mod, \"bias\", None) is not None:\n",
    "                yield f\"{mod_name}.bias\", mod.bias\n",
    "w_mins, w_maxs = [], []\n",
    "with torch.no_grad():\n",
    "    for _, w in iter_named_weight_tensors(model_fp, include_bias=True):\n",
    "        w_mins.append(float(w.min().item()))\n",
    "        w_maxs.append(float(w.max().item()))\n",
    "\n",
    "min_weight = min(w_mins)\n",
    "max_weight = max(w_maxs)\n",
    "num_weight_levels = 24\n",
    "if max_weight == min_weight:\n",
    "    raise ValueError(\"All weights are identical; quantization step would be zero.\")\n",
    "print(f\"Quant bounds: min_weight={min_weight:.6g}, max_weight={max_weight:.6g}, num_weight_levels={num_weight_levels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_qnoise(w: torch.Tensor, noise) -> torch.Tensor:\n",
    "    # noise.forward(w) should return same shape tensor\n",
    "    w_noisy = noise(w)\n",
    "    return torch.clamp(w_noisy, min=min_weight, max=max_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ccc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _functional_call(module: nn.Module, params: dict, buffers: dict, x: torch.Tensor):\n",
    "    # torch>=2.0: torch.func.functional_call\n",
    "    try:\n",
    "        from torch.func import functional_call as func_call\n",
    "        return func_call(module, (params, buffers), (x,))\n",
    "    except Exception:\n",
    "        from torch.nn.utils.stateless import functional_call as stateless_call\n",
    "        return stateless_call(module, params, (x,), buffers=buffers)\n",
    "\n",
    "class DiffModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps a base model, but runs forward with \"virtual\" modified weights:\n",
    "      mode = \"fp\" | \"quant\" | \"qnoise\"\n",
    "    \"\"\"\n",
    "    def __init__(self, base: nn.Module, mode: str, noise=None, include_bias: bool = True):\n",
    "        super().__init__()\n",
    "        assert mode in {\"fp\", \"quant\", \"qnoise\"}\n",
    "        self.base = base\n",
    "        self.mode = mode\n",
    "        self.noise = noise\n",
    "        self.include_bias = include_bias\n",
    "\n",
    "        # Cache target parameter names for Conv/Linear\n",
    "        self.target_param_names = set(name for name, _ in iter_named_weight_tensors(base, include_bias=include_bias))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Grab current params/buffers each call (safe even if base changes)\n",
    "        params = dict(self.base.named_parameters())\n",
    "        buffers = dict(self.base.named_buffers())\n",
    "\n",
    "        # Build overridden params dict\n",
    "        new_params = {}\n",
    "        for name, p in params.items():\n",
    "            if name in self.target_param_names:\n",
    "                w = p\n",
    "                if self.mode in {\"quant\", \"qnoise\"}:\n",
    "                    w = maskW(w)\n",
    "                if self.mode == \"qnoise\":\n",
    "                    if self.noise is None:\n",
    "                        raise ValueError(\"mode='qnoise' requires a noise object\")\n",
    "                    w = apply_qnoise(w, self.noise)\n",
    "                new_params[name] = w\n",
    "            else:\n",
    "                new_params[name] = p\n",
    "\n",
    "        return _functional_call(self.base, new_params, buffers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764171d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_fp = DiffModel(model_fp, mode=\"fp\").to(device).eval()\n",
    "fp_acc, fp_loss = evaluate_diff_model(diff_fp, test_loader, INPUT_SCALE, False, device=device)\n",
    "print(f\"FP32    test acc: {fp_acc:.2f}% | loss: {fp_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e792121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #num_weight_levels = 64\n",
    "# diff_q = DiffModel(model_fp, mode=\"quant\").to(device).eval()\n",
    "# q_acc, q_loss = evaluate_diff_model(diff_q, test_loader, INPUT_SCALE, False, device=device)\n",
    "# print(f\"QUANT   test acc: {q_acc:.2f}% | loss: {q_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "92c24921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q+NOISE test acc: 76.74% | loss: 1.4895\n"
     ]
    }
   ],
   "source": [
    "noise = SubthresholdPVTNoise()\n",
    "noise.update_params()\n",
    "diff_qn = DiffModel(model_fp, mode=\"qnoise\", noise=noise).to(device).eval()\n",
    "qn_acc, qn_loss = evaluate_diff_model(diff_qn, test_loader, INPUT_SCALE, False, device=device)\n",
    "print(f\"Q+NOISE test acc: {qn_acc:.2f}% | loss: {qn_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994a1c57",
   "metadata": {},
   "source": [
    "# Spiking Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DeltaSigmaEncoder:\n",
    "    \"\"\"Deterministic rate-to-spikes: spike count over T closely matches rate*T even for small T.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.acc = None\n",
    "\n",
    "    def reset(self, shape, device, dtype):\n",
    "        self.acc = torch.zeros(shape, device=device, dtype=dtype)\n",
    "\n",
    "    def step(self, rate01):\n",
    "        # rate01 in [0,1]\n",
    "        if self.acc is None or self.acc.shape != rate01.shape:\n",
    "            self.reset(rate01.shape, rate01.device, rate01.dtype)\n",
    "        self.acc += rate01\n",
    "        spk = (self.acc >= 1.0).to(rate01.dtype)\n",
    "        self.acc -= spk\n",
    "        return spk\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_softlif_with_spike_outputs(\n",
    "    soft_model,\n",
    "    test_loader,\n",
    "    T=12,                 # pick 6, 8, 12, 16\n",
    "    temp=1.0,             # softmax temperature for spike-rate outputs\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    \"\"\"\n",
    "    GUARANTEED same decision as soft_model if you use prob_rate (not noisy spikes) for argmax.\n",
    "    Also returns a spike-rate representation of the output using deterministic spikes.\n",
    "    \"\"\"\n",
    "    soft_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    enc = DeltaSigmaEncoder()\n",
    "\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        logits = soft_model(x)  # EXACT trained computation\n",
    "        probs = F.softmax(logits / temp, dim=1)  # in [0,1], sums to 1\n",
    "\n",
    "        # --- output \"spike rate\" representation ---\n",
    "        # We generate T-step spikes whose mean approximates probs (deterministic, low-variance)\n",
    "        enc.reset(probs.shape, probs.device, probs.dtype)\n",
    "        out_counts = torch.zeros_like(probs)\n",
    "\n",
    "        for _ in range(T):\n",
    "            out_spk = enc.step(probs)   # (B,C) spikes\n",
    "            out_counts += out_spk\n",
    "\n",
    "        out_rate = out_counts / float(T)  # \"spike rate\" per class\n",
    "\n",
    "        # IMPORTANT:\n",
    "        # If you want \"guaranteed same as soft_model\", use probs.argmax (or logits.argmax).\n",
    "        # If you want \"pure spiking decision\", use out_rate.argmax (can differ for tiny T).\n",
    "        pred = probs.argmax(dim=1)\n",
    "\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.numel()\n",
    "\n",
    "    return 100.0 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bb386",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = eval_softlif_with_spike_outputs(soft_model, test_loader, T=12, temp=1.0, device=device)\n",
    "print(\"SoftLIF accuracy (guaranteed):\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de67e527",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27211a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, glob, copy, re\n",
    "\n",
    "# # ---- find and load the best checkpoint (highest stored test_acc) ----\n",
    "# ckpt_dir = \"checkpoints/snntorch/diffEncoding/epoch_59_acc_74.1100.pt\"\n",
    "# ckpt_paths = sorted(glob.glob(os.path.join(ckpt_dir, \"*.pt\")))\n",
    "# if len(ckpt_paths) == 0:\n",
    "#     raise FileNotFoundError(f\"No checkpoints found in {ckpt_dir!r} (expected .pt files).\")\n",
    "\n",
    "# def _ckpt_score(path: str) -> float:\n",
    "#     try:\n",
    "#         obj = torch.load(path, map_location=\"cpu\")\n",
    "#         acc = obj.get(\"test_acc\", None)\n",
    "#         if isinstance(acc, (float, int)):\n",
    "#             return float(acc)\n",
    "#         if torch.is_tensor(acc):\n",
    "#             return float(acc.item())\n",
    "#     except Exception:\n",
    "#         pass\n",
    "#     # fallback: parse \"..._acc_<float>.pt\"\n",
    "#     m = re.search(r\"_acc_([0-9]*\\.?[0-9]+)\\.pt$\", os.path.basename(path))\n",
    "#     return float(m.group(1)) if m else -1.0\n",
    "\n",
    "# best_ckpt_path = max(ckpt_paths, key=_ckpt_score)\n",
    "# ckpt = torch.load(best_ckpt_path, map_location=\"cpu\")\n",
    "\n",
    "# print(\"Loaded checkpoint:\", best_ckpt_path)\n",
    "# print(\"Stored test_acc:\", ckpt.get(\"test_acc\", \"N/A\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8204e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ckpt_path = \"checkpoints/snntorch/diffEncoding/epoch_182_acc_73.1100.pt\"\n",
    "ckpt = torch.load(best_ckpt_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fc3915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "model_fp =  WideResNet_SoftLIFRate(\n",
    "        depth=16, widen_factor=10, dropout=0.0, num_classes=100,\n",
    "        in_channels=6\n",
    "    ).to(device)\n",
    "model_fp.load_state_dict(ckpt[\"state_dict\"], strict=True)\n",
    "INPUT_SCALE = estimate_input_scale(train_loader, device=device, batches=50, q=0.99)\n",
    "fp_loss, fp_acc = evaluate_diff_model(model_fp, test_loader, INPUT_SCALE, False, device=device)\n",
    "print(f\"FP32   test acc: {fp_acc:.2f}% | loss: {fp_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2563a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp = WideResNet(depth=28, widen_factor=10, dropout=0.0, num_classes=100).to(device)\n",
    "model_fp.load_state_dict(ckpt[\"state_dict\"], strict=True)\n",
    "\n",
    "fp_loss, fp_acc = evaluate(model_fp, test_loader)\n",
    "print(f\"FP32   test acc: {fp_acc*100:.2f}% | loss: {fp_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cea9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _iter_weight_tensors(m: nn.Module):\n",
    "    for mod in m.modules():\n",
    "        if isinstance(mod, (nn.Conv2d, nn.Linear)):\n",
    "            if getattr(mod, \"weight\", None) is not None:\n",
    "                yield mod.weight\n",
    "            if getattr(mod, \"bias\", None) is not None:\n",
    "                yield mod.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf4a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_mins, w_maxs = [], []\n",
    "with torch.no_grad():\n",
    "    for w in _iter_weight_tensors(model_fp):\n",
    "        w_mins.append(float(w.min().item()))\n",
    "        w_maxs.append(float(w.max().item()))\n",
    "\n",
    "min_weight = min(w_mins)\n",
    "max_weight = max(w_maxs)\n",
    "num_w_levels = 64  # change if needed (e.g., 8, 32, 256)\n",
    "\n",
    "if max_weight == min_weight:\n",
    "    raise ValueError(\"All weights are identical; quantization step would be zero.\")\n",
    "\n",
    "print(f\"Quant bounds: min_weight={min_weight:.6g}, max_weight={max_weight:.6g}, num_w_levels={num_w_levels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57184c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskW(w):\n",
    "    w = torch.clamp(w, min=min_weight, max=max_weight)\n",
    "    step = (max_weight - min_weight) / (num_w_levels - 1)\n",
    "    return ((w - min_weight) / step).round() * step + min_weight\n",
    "\n",
    "@torch.no_grad()\n",
    "def apply_quantization_(m: nn.Module):\n",
    "    for w in _iter_weight_tensors(m):\n",
    "        w.copy_(maskW(w))\n",
    "\n",
    "model_q = WideResNet(depth=28, widen_factor=10, dropout=0.0, num_classes=100).to(device)\n",
    "model_q.load_state_dict(model_fp.state_dict(), strict=True)\n",
    "apply_quantization_(model_q)\n",
    "\n",
    "q_loss, q_acc = evaluate(model_q, test_loader)\n",
    "print(f\"QUANT  test acc: {q_acc*100:.2f}% | loss: {q_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ff32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "k: float = 1.38e-23   # Boltzmann constant (J/K)\n",
    "q: float = 1.602176634e-19\n",
    "T_r: float = 300\n",
    "n: float = 1.5\n",
    "k_mu: float = 1.5\n",
    "k_vt: float = 1e-3 # Typical value for threshold voltage temperature dependence (in V/K)\n",
    "Tr = 300\n",
    "\n",
    "def thermal_voltage(T):\n",
    "    return k * T / q\n",
    "\n",
    "def Id_subthreshold(W, L, mu, Cox, Vth, VGS, VDS, T, n):\n",
    "    Vt = thermal_voltage(T)\n",
    "    Is0 = (W / L) * mu * Cox * (Vt**2) * np.exp(1.8)\n",
    "    return Is0 * np.exp((VGS - Vth) / (n * Vt)) * (1 - np.exp(-VDS / Vt))\n",
    "\n",
    "class SubthresholdPVTNoise:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        params: dict with\n",
    "            W, L, mu, Cox, Vth, VGS, VDS, T, n\n",
    "        sigmas: dict with\n",
    "            W, L, mu, Cox, Vth, VDS (normal std)\n",
    "            dT (uniform half-range)\n",
    "        \"\"\"\n",
    "        #self.p = params\n",
    "        self.W   = 44e-9\n",
    "        self.L   = 22e-9\n",
    "        self.mu  = 0.03\n",
    "        self.Cox = 0.03\n",
    "        self.Vth = 0.35\n",
    "        self.VGS = 0.25\n",
    "        self.VDS = 0.8\n",
    "        self.T0  = 310\n",
    "        self.n   = n\n",
    "        self.dId_dW_value = 0\n",
    "        self.dId_dL_value = 0\n",
    "        self.dId_dmu_value = 0\n",
    "        self.dId_dCox_value = 0\n",
    "        self.dId_dVth_value = 0\n",
    "        self.dId_dVDS_value = 0\n",
    "        self.dId_dT_value = 0\n",
    "        self.s = {\n",
    "            \"W\":   0.10 * self.W,\n",
    "            \"L\":   0.10 * self.L,\n",
    "            \"mu\":  0.10 * self.mu,\n",
    "            \"Cox\": 0.10 * self.Cox,\n",
    "            \"Vth\": 0.10 * self.Vth,\n",
    "            \"VDS\": 0.10 * self.VDS,\n",
    "            \"T_min\": 248,\n",
    "            \"T_max\": 398,\n",
    "        }\n",
    "\n",
    "    def dId_dW(self):\n",
    "        Vt = thermal_voltage(self.T0)\n",
    "        return (self.mu * self.Cox * Vt**2 / self.L) * np.exp(1.8) * \\\n",
    "            np.exp((self.VGS - self.Vth) / (self.n * Vt)) * (1 - np.exp(self.VDS / Vt))\n",
    "\n",
    "    def dId_dmu(self):\n",
    "        Vt = thermal_voltage(self.T0)\n",
    "        return (self.W * self.Cox * Vt**2 / self.L) * np.exp(1.8) * \\\n",
    "            np.exp((self.VGS - self.Vth) / (self.n * Vt)) * (1 - np.exp(self.VDS / Vt))\n",
    "\n",
    "    def dId_dCox(self):\n",
    "        Vt = thermal_voltage(self.T0)\n",
    "        return (self.W * self.mu * Vt**2 / self.L) * np.exp(1.8) * \\\n",
    "            np.exp((self.VGS - self.Vth) / (self.n * Vt)) * (1 - np.exp(self.VDS / Vt))\n",
    "\n",
    "    def dId_dL(self):\n",
    "        Vt = thermal_voltage(self.T0)\n",
    "        return -(self.W * self.mu * self.Cox * Vt**2 / self.L**2) * np.exp(1.8) * \\\n",
    "                np.exp((self.VGS - self.Vth) / (self.n * Vt)) * (1 - np.exp(self.VDS / Vt))\n",
    "    \n",
    "    def dId_dVDS(self):\n",
    "        Vt = thermal_voltage(self.T0)\n",
    "        Is0 = (-1 / Vt) * (self.W / self.L) * self.mu * self.Cox * Vt**2 * np.exp(1.8)\n",
    "        return Is0 * np.exp((self.VGS - self.Vth) / (self.n * Vt)) * \\\n",
    "            np.exp(self.VDS / Vt)\n",
    "    \n",
    "    def dId_dVth(self):\n",
    "        Id = Id_subthreshold(self.W, self.L, self.mu, self.Cox, self.Vth, self.VGS, self.VDS, self.T0, self.n)\n",
    "        Vt = thermal_voltage(self.T0)\n",
    "        return (-1 / (self.n * Vt)) * Id * np.exp((self.VGS - self.Vth) / (self.n * Vt)) * \\\n",
    "            (1 - np.exp(self.VDS / Vt))\n",
    "\n",
    "    def dId_dT(self):\n",
    "        Vt = thermal_voltage(self.T0)\n",
    "        Id = Id_subthreshold(self.W, self.L, self.mu, self.Cox, self.Vth, self.VGS, self.VDS, self.T0, self.n)\n",
    "\n",
    "        term1 = k_mu - (( k_vt * self.T0) / (self.n * Vt)) * Id\n",
    "        term2 = (1 - np.exp(self.VDS / Vt)) * Tr**(-k_mu) * self.T0**(k_mu - 1)\n",
    "        term3 = np.exp((self.VGS - self.Vth * Tr - k_vt * (self.T0-Tr)) / (self.n * Vt))\n",
    "        return Id * (term1 + term2 + term3)\n",
    "\n",
    "    def update_params(self, **kwargs):\n",
    "        self.p.update(kwargs)\n",
    "        self.dId_dW_value = self.dId_dW()\n",
    "        self.dId_dL_value = self.dId_dL()\n",
    "        self.dId_dmu_value = self.dId_dmu()\n",
    "        self.dId_dCox_value = self.dId_dCox()\n",
    "        self.dId_dVth_value = self.dId_dVth()\n",
    "        self.dId_dVDS_value = self.dId_dVDS()\n",
    "        self.dId_dT_value = self.dId_dT()\n",
    "\n",
    "    def forward(self, Id0):\n",
    "        \"\"\"\n",
    "        Id0: torch.Tensor (any shape)\n",
    "        returns: noisy Id tensor (same shape)\n",
    "        \"\"\"\n",
    "        device, dtype = Id0.device, Id0.dtype\n",
    "\n",
    "        # ---- sample parameter variations ----\n",
    "        dW   = torch.normal(0.0, self.s[\"W\"],   Id0.shape, device=device, dtype=dtype)\n",
    "        dL   = torch.normal(0.0, self.s[\"L\"],   Id0.shape, device=device, dtype=dtype)\n",
    "        dmu  = torch.normal(0.0, self.s[\"mu\"],  Id0.shape, device=device, dtype=dtype)\n",
    "        dCox = torch.normal(0.0, self.s[\"Cox\"], Id0.shape, device=device, dtype=dtype)\n",
    "        dVth = torch.normal(0.0, self.s[\"Vth\"], Id0.shape, device=device, dtype=dtype)\n",
    "        dVDS = torch.normal(0.0, self.s[\"VDS\"], Id0.shape, device=device, dtype=dtype)\n",
    "        dT   = torch.empty_like(Id0).uniform_(self.s[\"T_min\"], self.s[\"T_max\"])\n",
    "\n",
    "        # dW = 0\n",
    "        # dL = 0\n",
    "        # dmu = 0\n",
    "        # dCox = 0    \n",
    "        # dVth = 0\n",
    "        # dVDS = 0\n",
    "        # dT = 0\n",
    "\n",
    "        # ---- analytical partial derivatives ----\n",
    "        dId = (\n",
    "            self.dId_dW_value           * dW   +\n",
    "            self.dId_dL_value           * dL   +\n",
    "            self.dId_dmu_value          * dmu  +\n",
    "            self.dId_dCox_value         * dCox +\n",
    "            self.dId_dVth_value         * dVth +\n",
    "            self.dId_dVDS_value * dVDS +\n",
    "            self.dId_dT_value * dT\n",
    "        )\n",
    "\n",
    "        return Id0 + dId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4529189",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def apply_noise_(m: nn.Module, noise: SubthresholdPVTNoise):\n",
    "    for w in _iter_weight_tensors(m):\n",
    "        w_noisy = noise.forward(w)\n",
    "        w.copy_(torch.clamp(w_noisy, min=min_weight, max=max_weight))\n",
    "\n",
    "noise = SubthresholdPVTNoise()\n",
    "\n",
    "model_qn = WideResNet(depth=28, widen_factor=10, dropout=0.0, num_classes=100).to(device)\n",
    "model_qn.load_state_dict(model_fp.state_dict(), strict=True)\n",
    "apply_noise_(model_qn, noise)\n",
    "\n",
    "qn_loss, qn_acc = evaluate(model_qn, test_loader)\n",
    "print(f\"Q+NOISE test acc: {qn_acc*100:.2f}% | loss: {qn_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_retention_noise(model_weights, std_ret_high, std_ret_low, threshold = 0.06):\n",
    "    \"\"\"\n",
    "    Adds noise to trained weights based on a threshold and clamps the weights within a given range.\n",
    "    \n",
    "    Args:\n",
    "        model_weights (torch.Tensor): The tensor of trained weights.\n",
    "        std_ret_high (float): The standard deviation for noise applied to weights >= threshold.\n",
    "        std_ret_low (float): The standard deviation for noise applied to weights < threshold.\n",
    "        threshold (float): The threshold to separate high and low noise application.\n",
    "        min_weight (float): The minimum value to clamp weights to.\n",
    "        max_weight (float): The maximum value to clamp weights to.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: The modified weights after noise addition and clamping.\n",
    "    \"\"\"\n",
    "    # Create a mask for weights below the threshold\n",
    "    mask_low = model_weights < threshold\n",
    "\n",
    "    # Generate noise for weights below and above the threshold\n",
    "    noise_low = torch.abs(torch.normal(0, std_ret_low, size=model_weights.size()))\n",
    "    noise_high = torch.abs(torch.normal(0, std_ret_high, size=model_weights.size()))\n",
    "    \n",
    "    # Select the appropriate noise based on the mask\n",
    "    ret_noise = torch.where(mask_low, noise_low, noise_high)\n",
    "    \n",
    "    return model_weights + ret_noise\n",
    "\n",
    "def apply_quant_noise(model_weights, low0 = 0.24, high0 = 0.3):\n",
    "    \"\"\"\n",
    "    Applies noise to the trained weights based on specified ranges, keeping them part of the computational graph.\n",
    "    \n",
    "    Args:\n",
    "        model_weights (torch.Tensor): The trained weights to which noise will be applied.\n",
    "        low0 (float): Lower bound for the first range of noise application.\n",
    "        high0 (float): Upper bound for the first range of noise application.\n",
    "        max_weight (float): Maximum weight for the second range of noise application.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: The updated weights with noise applied, part of the computational graph.\n",
    "    \"\"\"\n",
    "    global max_weight\n",
    "\n",
    "    # First range: [low0, high0]\n",
    "    mask0 = (model_weights > low0) & (model_weights < high0)\n",
    "    random_values0 = low0 + (high0 - low0) * torch.abs(torch.randn_like(model_weights))\n",
    "    random_values0 = torch.where(mask0, random_values0, torch.zeros_like(model_weights))\n",
    "    \n",
    "    # Second range: [high0, max_weight + 0.01]\n",
    "    low1, high1 = high0, max_weight + 0.01\n",
    "    mask1 = (model_weights > low1) & (model_weights < high1)\n",
    "    random_values1 = low1 + (high1 - low1) * torch.abs(torch.randn_like(model_weights))\n",
    "    random_values1 = torch.where(mask1, random_values1, torch.zeros_like(model_weights))\n",
    "    \n",
    "    return model_weights + random_values0 + random_values1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rezvan-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
